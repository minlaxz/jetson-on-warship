mqtt:
  enabled: True
  host: frigate-mqtt
  port: 1883
  topic_prefix: frigate
  client_id: frigate
  stats_interval: 30

detectors:
  tensorrt:
    type: tensorrt
    device: 0

database:
  path: /config/frigate.db

model:
  path: /config/model_cache/tensorrt/yolov7-320.trt
  width: 320
  height: 320
  input_pixel_format: rgb
  input_tensor: nchw
  # Optional: Object detection model type, currently only used with the OpenVINO detector
  # Valid values are ssd, yolox (default: shown below)
  #model_type: ssd
  # Optional: Label name modifications. These are merged into the standard labelmap.
  #labelmap:
  #  2: vehicle

audio:
  enabled: False
  max_not_heard: 30
  # Optional: Configure the min rms volume required to run audio detection (default: shown below)
  # As a rule of thumb:
  #  - 200 - high sensitivity
  #  - 500 - medium sensitivity
  #  - 1000 - low sensitivity
  min_volume: 500
  listen:
    - bark
    - fire_alarm
    - scream
    - speech
    - yell
  filters:
    speech:
      threshold: 0.8

logger:
  default: info
  logs:
    frigate.event: debug

environment_vars:
  EXAMPLE_VAR: value

birdseye:
  enabled: True
  # Optional: Restream birdseye via RTSP (default: shown below)
  # NOTE: Enabling this will set birdseye to run 24/7 which may increase CPU usage somewhat.
  restream: False
  # Optional: Width of the output resolution (default: shown below)
  width: 1280
  # Optional: Height of the output resolution (default: shown below)
  height: 720
  # Optional: Encoding quality of the mpeg1 feed (default: shown below)
  # 1 is the highest quality, and 31 is the lowest. Lower quality feeds utilize less CPU resources.
  quality: 8
  # Optional: Mode of the view. Available options are: objects, motion, and continuous
  #   objects - cameras are included if they have had a tracked object within the last 30 seconds
  #   motion - cameras are included if motion was detected in the last 30 seconds
  #   continuous - all cameras are included always
  mode: objects
  # Optional: Threshold for camera activity to stop showing camera (default: shown below)
  inactivity_threshold: 30
  # Optional: Configure the birdseye layout
  layout:
    # Optional: Scaling factor for the layout calculator (default: shown below)
    scaling_factor: 2.0
    # Optional: Maximum number of cameras to show at one time, showing the most recent (default: show all cameras)
    max_cameras: 1

# Optional: ffmpeg configuration
# More information about presets at https://docs.frigate.video/configuration/ffmpeg_presets
ffmpeg:
  global_args: -hide_banner -loglevel warning -threads 2
  hwaccel_args: preset-jetson-h264
  input_args: preset-rtsp-generic
  output_args:
    detect: -threads 2 -f rawvideo -pix_fmt yuv420p
    record: preset-record-generic
    rtmp: preset-rtmp-generic
  # Optional: Time in seconds to wait before ffmpeg retries connecting to the camera. (default: shown below)
  # If set too low, frigate will retry a connection to the camera's stream too frequently, using up the limited streams some cameras can allow at once
  # If set too high, then if a ffmpeg crash or camera stream timeout occurs, you could potentially lose up to a maximum of retry_interval second(s) of footage
  # NOTE: this can be a useful setting for Wireless / Battery cameras to reduce how much footage is potentially lost during a connection timeout.
  retry_interval: 10

detect:
  width: 1280
  height: 720
  fps: 5
  enabled: True
  min_initialized: 2
  max_disappeared: 25
  stationary:
    # Optional: Frequency for confirming stationary objects (default: same as threshold)
    # When set to 1, object detection will run to confirm the object still exists on every frame.
    # If set to 10, object detection will run to confirm the object still exists on every 10th frame.
    interval: 50
    # Optional: Number of frames without a position change for an object to be considered stationary (default: 10x the frame rate or 10s)
    threshold: 50
    # Optional: Define a maximum number of frames for tracking a stationary object (default: not set, track forever)
    # This can help with false positives for objects that should only be stationary for a limited amount of time.
    # It can also be used to disable stationary object tracking. For example, you may want to set a value for person, but leave
    # car at the default.
    # WARNING: Setting these values overrides default behavior and disables stationary object tracking.
    #          There are very few situations where you would want it disabled. It is NOT recommended to
    #          copy these values from the example config into your config unless you know they are needed.
    max_frames:
      # Optional: Default for all object types (default: not set, track forever)
      default: 3000
      # Optional: Object specific values
      objects:
        person: 1000
  annotation_offset: 0

# # Optional: Object configuration
# # NOTE: Can be overridden at the camera level
# objects:
#   # Optional: list of objects to track from labelmap.txt (default: shown below)
#   track:
#     - person
#   # Optional: mask to prevent all object types from being detected in certain areas (default: no mask)
#   # Checks based on the bottom center of the bounding box of the object.
#   # NOTE: This mask is COMBINED with the object type specific mask below
#   mask: 0,0,1000,0,1000,200,0,200
#   # Optional: filters to reduce false positives for specific object types
#   filters:
#     person:
#       # Optional: minimum width*height of the bounding box for the detected object (default: 0)
#       min_area: 5000
#       # Optional: maximum width*height of the bounding box for the detected object (default: 24000000)
#       max_area: 100000
#       # Optional: minimum width/height of the bounding box for the detected object (default: 0)
#       min_ratio: 0.5
#       # Optional: maximum width/height of the bounding box for the detected object (default: 24000000)
#       max_ratio: 2.0
#       # Optional: minimum score for the object to initiate tracking (default: shown below)
#       min_score: 0.5
#       # Optional: minimum decimal percentage for tracked object's computed score to be considered a true positive (default: shown below)
#       threshold: 0.7
#       # Optional: mask to prevent this object type from being detected in certain areas (default: no mask)
#       # Checks based on the bottom center of the bounding box of the object
#       mask: 0,0,1000,0,1000,200,0,200

# # Optional: Motion configuration
# # NOTE: Can be overridden at the camera level
# motion:
#   # Optional: The threshold passed to cv2.threshold to determine if a pixel is different enough to be counted as motion. (default: shown below)
#   # Increasing this value will make motion detection less sensitive and decreasing it will make motion detection more sensitive.
#   # The value should be between 1 and 255.
#   threshold: 30
#   # Optional: The percentage of the image used to detect lightning or other substantial changes where motion detection
#   #           needs to recalibrate. (default: shown below)
#   # Increasing this value will make motion detection more likely to consider lightning or ir mode changes as valid motion.
#   # Decreasing this value will make motion detection more likely to ignore large amounts of motion such as a person approaching
#   # a doorbell camera.
#   lightning_threshold: 0.8
#   # Optional: Minimum size in pixels in the resized motion image that counts as motion (default: shown below)
#   # Increasing this value will prevent smaller areas of motion from being detected. Decreasing will
#   # make motion detection more sensitive to smaller moving objects.
#   # As a rule of thumb:
#   #  - 10 - high sensitivity
#   #  - 30 - medium sensitivity
#   #  - 50 - low sensitivity
#   contour_area: 10
#   # Optional: Alpha value passed to cv2.accumulateWeighted when averaging frames to determine the background (default: shown below)
#   # Higher values mean the current frame impacts the average a lot, and a new object will be averaged into the background faster.
#   # Low values will cause things like moving shadows to be detected as motion for longer.
#   # https://www.geeksforgeeks.org/background-subtraction-in-an-image-using-concept-of-running-average/
#   frame_alpha: 0.01
#   # Optional: Height of the resized motion frame  (default: 100)
#   # Higher values will result in more granular motion detection at the expense of higher CPU usage.
#   # Lower values result in less CPU, but small changes may not register as motion.
#   frame_height: 100
#   # Optional: motion mask
#   # NOTE: see docs for more detailed info on creating masks
#   mask: 0,900,1080,900,1080,1920,0,1920
#   # Optional: improve contrast (default: shown below)
#   # Enables dynamic contrast improvement. This should help improve night detections at the cost of making motion detection more sensitive
#   # for daytime.
#   improve_contrast: True
#   # Optional: Delay when updating camera motion through MQTT from ON -> OFF (default: shown below).
#   mqtt_off_delay: 30

# Optional: Record configuration
# NOTE: Can be overridden at the camera level
record:
  # Optional: Enable recording (default: shown below)
  # WARNING: If recording is disabled in the config, turning it on via
  #          the UI or MQTT later will have no effect.
  enabled: True
  # Optional: Number of minutes to wait between cleanup runs (default: shown below)
  # This can be used to reduce the frequency of deleting recording segments from disk if you want to minimize i/o
  expire_interval: 60
  # Optional: Sync recordings with disk on startup and once a day (default: shown below).
  sync_recordings: False
  # Optional: Retention settings for recording
  retain:
    # Optional: Number of days to retain recordings regardless of events (default: shown below)
    # NOTE: This should be set to 0 and retention should be defined in events section below
    #       if you only want to retain recordings of events.
    days: 0
    # Optional: Mode for retention. Available options are: all, motion, and active_objects
    #   all - save all recording segments regardless of activity
    #   motion - save all recordings segments with any detected motion
    #   active_objects - save all recording segments with active/moving objects
    # NOTE: this mode only applies when the days setting above is greater than 0
    mode: active_objects
  # Optional: Recording Export Settings
  export:
    # Optional: Timelapse Output Args (default: shown below).
    # NOTE: The default args are set to fit 24 hours of recording into 1 hour playback.
    # See https://stackoverflow.com/a/58268695 for more info on how these args work.
    # As an example: if you wanted to go from 24 hours to 30 minutes that would be going
    # from 86400 seconds to 1800 seconds which would be 1800 / 86400 = 0.02.
    # The -r (framerate) dictates how smooth the output video is.
    # So the args would be -vf setpts=0.02*PTS -r 30 in that case.
    timelapse_args: "-vf setpts=0.04*PTS -r 30"
  # Optional: Event recording settings
  events:
    # Optional: Number of seconds before the event to include (default: shown below)
    pre_capture: 10
    # Optional: Number of seconds after the event to include (default: shown below)
    post_capture: 10
    # Optional: Objects to save recordings for. (default: all tracked objects)
    objects:
      - person
    # Optional: Restrict recordings to objects that entered any of the listed zones (default: no required zones)
    required_zones: []
    # Optional: Retention settings for recordings of events
    retain:
      # Required: Default retention days (default: shown below)
      default: 10
      # Optional: Mode for retention. (default: shown below)
      #   all - save all recording segments for events regardless of activity
      #   motion - save all recordings segments for events with any detected motion
      #   active_objects - save all recording segments for event with active/moving objects
      #
      # NOTE: If the retain mode for the camera is more restrictive than the mode configured
      #       here, the segments will already be gone by the time this mode is applied.
      #       For example, if the camera retain mode is "motion", the segments without motion are
      #       never stored, so setting the mode to "all" here won't bring them back.
      mode: motion
      # Optional: Per object retention days
      objects:
        person: 15

# Optional: Configuration for the jpg snapshots written to the clips directory for each event
# NOTE: Can be overridden at the camera level
snapshots:
  # Optional: Enable writing jpg snapshot to /media/frigate/clips (default: shown below)
  enabled: True
  # Optional: save a clean PNG copy of the snapshot image (default: shown below)
  clean_copy: True
  # Optional: print a timestamp on the snapshots (default: shown below)
  timestamp: True
  # Optional: draw bounding box on the snapshots (default: shown below)
  bounding_box: True
  # Optional: crop the snapshot (default: shown below)
  crop: False
  # Optional: height to resize the snapshot to (default: original size)
  height: 175
  # Optional: Restrict snapshots to objects that entered any of the listed zones (default: no required zones)
  required_zones: []
  # Optional: Camera override for retention settings (default: global values)
  retain:
    # Required: Default retention days (default: shown below)
    default: 10
    # Optional: Per object retention days
    objects:
      person: 15
  # Optional: quality of the encoded jpeg, 0-100 (default: shown below)
  quality: 70

# Optional: RTMP configuration
# NOTE: RTMP is deprecated in favor of restream
# NOTE: Can be overridden at the camera level
rtmp:
  # Optional: Enable the RTMP stream (default: False)
  enabled: False

# Optional: Restream configuration
# Uses https://github.com/AlexxIT/go2rtc (v1.8.3)
go2rtc:
  streams:
    outdoor_rtsp_cam:
      - rtsp://admin:L20E52F6@192.168.0.111:554/cam/realmonitor?channel=1&subtype=0
      #- rtsp://192.168.1.5:554/live0 # <- stream which supports video & aac audio. This is only supported for rtsp streams, http must use ffmpeg
      #- "ffmpeg:name_your_rtsp_cam#audio=opus" # <- copy of the stream which transcodes audio to opus
    outdoor_rtsp_cam_sub:
      - rtsp://admin:L20E52F6@192.168.0.111:554/cam/realmonitor?channel=1&subtype=1
      #- rtsp://192.168.1.5:554/substream # <- stream which supports video & aac audio. This is only supported for rtsp streams, http must use ffmpeg
      #- "ffmpeg:name_your_rtsp_cam_sub#audio=opus" # <- copy of the stream which transcodes audio to opus

# # Optional: jsmpeg stream configuration for WebUI
# live:
#   # Optional: Set the name of the stream that should be used for live view
#   # in frigate WebUI. (default: name of camera)
#   stream_name: outdoor_rtsp_cam
#   # Optional: Set the height of the jsmpeg stream. (default: 720)
#   # This must be less than or equal to the height of the detect stream. Lower resolutions
#   # reduce bandwidth required for viewing the jsmpeg stream. Width is computed to match known aspect ratio.
#   height: 720
#   # Optional: Set the encode quality of the jsmpeg stream (default: shown below)
#   # 1 is the highest quality, and 31 is the lowest. Lower quality feeds utilize less CPU resources.
#   quality: 8

# Optional: in-feed timestamp style configuration
# NOTE: Can be overridden at the camera level
#timestamp_style:
  # Optional: Position of the timestamp (default: shown below)
  #           "tl" (top left), "tr" (top right), "bl" (bottom left), "br" (bottom right)
  #position: "tl"
  # Optional: Format specifier conform to the Python package "datetime" (default: shown below)
  #           Additional Examples:
  #             german: "%d.%m.%Y %H:%M:%S"
  #format: "%m/%d/%Y %H:%M:%S"
  # Optional: Color of font
  #color:
    # All Required when color is specified (default: shown below)
    #red: 255
    #green: 255
    #blue: 255
  # Optional: Line thickness of font (default: shown below)
  #thickness: 2
  # Optional: Effect of lettering (default: shown below)
  #           None (No effect),
  #           "solid" (solid background in inverse color of font)
  #           "shadow" (shadow for font)
  #effect: None

# Required
cameras:
  # Required: name of the camera
  outdoor_camera:
    # Optional: Enable/Disable the camera (default: shown below).
    # If disabled: config is used but no live stream and no capture etc.
    # Events/Recordings are still viewable.
    enabled: True
    # Required: ffmpeg settings for the camera
    ffmpeg:
      # Required: A list of input streams for the camera. See documentation for more information.
      inputs:
        # Required: the path to the stream
        # NOTE: path may include environment variables or docker secrets, which must begin with 'FRIGATE_' and be referenced in {}
        - path: rtsp://127.0.0.1:8554/outdoor_rtsp_cam
          # Required: list of roles for this stream. valid values are: audio,detect,record,rtmp
          # NOTICE: In addition to assigning the audio, record, and rtmp roles,
          # they must also be enabled in the camera config.
          roles:
            - audio
            - record
          # Optional: camera specific hwaccel args (default: inherit)
          hwaccel_args: preset-jetson-h265
          # Optional: camera specific global args (default: inherit)
          # global_args:
          # Optional: stream specific input args (default: inherit)
          # input_args:
          # Optional: camera specific output args (default: inherit)
          # output_args:
        - path: rtsp://127.0.0.1:8554/outdoor_rtsp_cam_sub
          roles:
            - detect
          hwaccel_args: preset-jetson-h264
      # Optional: camera specific global args (default: inherit)
      # global_args:
      # Optional: camera specific hwaccel args (default: inherit)
      # hwaccel_args:
      # Optional: camera specific input args (default: inherit)
      # input_args:
      # Optional: camera specific output args (default: inherit)
      # output_args:
    live:
      stream_name: outdoor_rtsp_cam_sub
    # Optional: timeout for highest scoring image before allowing it
    # to be replaced by a newer image. (default: shown below)
    best_image_timeout: 60

    # Optional: URL to visit the camera web UI directly from the system page. Might not be available on every camera.
    webui_url: ""

    # Optional: zones for this camera
    zones:
      # Required: name of the zone
      # NOTE: This must be different than any camera names, but can match with another zone on another
      #       camera.
      front_steps:
        # Required: List of x,y coordinates to define the polygon of the zone.
        # NOTE: Presence in a zone is evaluated only based on the bottom center of the objects bounding box.
        coordinates: 545,1077,747,939,788,805
        # Optional: Number of consecutive frames required for object to be considered present in the zone (default: shown below).
        inertia: 3
        # Optional: List of objects that can trigger this zone (default: all tracked objects)
        objects:
          - person
        # Optional: Zone level object filters.
        # NOTE: The global and camera filters are applied upstream.
        filters:
          person:
            min_area: 5000
            max_area: 100000
            threshold: 0.7

    # Optional: Configuration for the jpg snapshots published via MQTT
    mqtt:
      # Optional: Enable publishing snapshot via mqtt for camera (default: shown below)
      # NOTE: Only applies to publishing image data to MQTT via 'frigate/<camera_name>/<object_name>/snapshot'.
      # All other messages will still be published.
      enabled: True
      # Optional: print a timestamp on the snapshots (default: shown below)
      timestamp: True
      # Optional: draw bounding box on the snapshots (default: shown below)
      bounding_box: True
      # Optional: crop the snapshot (default: shown below)
      crop: True
      # Optional: height to resize the snapshot to (default: shown below)
      height: 270
      # Optional: jpeg encode quality (default: shown below)
      quality: 70
      # Optional: Restrict mqtt messages to objects that entered any of the listed zones (default: no required zones)
      required_zones: []

    # Optional: Configuration for how camera is handled in the GUI.
    ui:
      # Optional: Adjust sort order of cameras in the UI. Larger numbers come later (default: shown below)
      # By default the cameras are sorted alphabetically.
      order: 0
      # Optional: Whether or not to show the camera in the Frigate UI (default: shown below)
      dashboard: True

    # Optional: connect to ONVIF camera
    # to enable PTZ controls.
    onvif:
      # Required: host of the camera being connected to.
      host: 192.168.0.111
      # Optional: ONVIF port for device (default: shown below).
      port: 80
      # Optional: username for login.
      # NOTE: Some devices require admin to access ONVIF.
      user: admin
      # Optional: password for login.
      password: L20E52F6
      # Optional: PTZ camera object autotracking. Keeps a moving object in
      # the center of the frame by automatically moving the PTZ camera.
      autotracking:
        # Optional: enable/disable object autotracking. (default: shown below)
        enabled: False
        # Optional: calibrate the camera on startup (default: shown below)
        # A calibration will move the PTZ in increments and measure the time it takes to move.
        # The results are used to help estimate the position of tracked objects after a camera move.
        # Frigate will update your config file automatically after a calibration with
        # a "movement_weights" entry for the camera. You should then set calibrate_on_startup to False.
        calibrate_on_startup: False
        # Optional: the mode to use for zooming in/out on objects during autotracking. (default: shown below)
        # Available options are: disabled, absolute, and relative
        #   disabled - don't zoom in/out on autotracked objects, use pan/tilt only
        #   absolute - use absolute zooming (supported by most PTZ capable cameras)
        #   relative - use relative zooming (not supported on all PTZs, but makes concurrent pan/tilt/zoom movements)
        zooming: disabled
        # Optional: A value to change the behavior of zooming on autotracked objects. (default: shown below)
        # A lower value will keep more of the scene in view around a tracked object.
        # A higher value will zoom in more on a tracked object, but Frigate may lose tracking more quickly.
        # The value should be between 0.1 and 0.75
        zoom_factor: 0.3
        # Optional: list of objects to track from labelmap.txt (default: shown below)
        track:
          - person
        # Required: Begin automatically tracking an object when it enters any of the listed zones.
        required_zones:
          - zone_name
        # Required: Name of ONVIF preset in camera's firmware to return to when tracking is over. (default: shown below)
        return_preset: home
        # Optional: Seconds to delay before returning to preset. (default: shown below)
        timeout: 10
        # Optional: Values generated automatically by a camera calibration. Do not modify these manually. (default: shown below)
        # movement_weights: []

    # Optional: Configuration for how to sort the cameras in the Birdseye view.
    birdseye:
      # Optional: Adjust sort order of cameras in the Birdseye view. Larger numbers come later (default: shown below)
      # By default the cameras are sorted alphabetically.
      order: 0

# Optional
ui:
  # Optional: Set the default live mode for cameras in the UI (default: shown below)
  live_mode: mse
  # Optional: Set a timezone to use in the UI (default: use browser local time)
  # timezone: America/Denver
  # Optional: Use an experimental recordings / camera view UI (default: shown below)
  use_experimental: False
  # Optional: Set the time format used.
  # Options are browser, 12hour, or 24hour (default: shown below)
  time_format: browser
  # Optional: Set the date style for a specified length.
  # Options are: full, long, medium, short
  # Examples:
  #    short: 2/11/23
  #    medium: Feb 11, 2023
  #    full: Saturday, February 11, 2023
  # (default: shown below).
  date_style: short
  # Optional: Set the time style for a specified length.
  # Options are: full, long, medium, short
  # Examples:
  #    short: 8:14 PM
  #    medium: 8:15:22 PM
  #    full: 8:15:22 PM Mountain Standard Time
  # (default: shown below).
  time_style: medium
  # Optional: Ability to manually override the date / time styling to use strftime format
  # https://www.gnu.org/software/libc/manual/html_node/Formatting-Calendar-Time.html
  # possible values are shown above (default: not set)
  strftime_fmt: "%Y/%m/%d %H:%M"

# Optional: Telemetry configuration
telemetry:
  # Optional: Enabled network interfaces for bandwidth stats monitoring (default: empty list, let nethogs search all)
  network_interfaces:
    - eth
    - enp
    - eno
    - ens
    - wl
    - lo
  # Optional: Configure system stats
  stats:
    # Enable AMD GPU stats (default: shown below)
    amd_gpu_stats: True
    # Enable Intel GPU stats (default: shown below)
    intel_gpu_stats: True
    # Enable network bandwidth stats monitoring for camera ffmpeg processes, go2rtc, and object detectors. (default: shown below)
    # NOTE: The container must either be privileged or have cap_net_admin, cap_net_raw capabilities enabled.
    network_bandwidth: True
  # Optional: Enable the latest version outbound check (default: shown below)
  # NOTE: If you use the HomeAssistant integration, disabling this will prevent it from reporting new versions
  version_check: True
